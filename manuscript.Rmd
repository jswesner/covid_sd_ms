---
title: "Forecasting hospitalizations due to COVID-19 in South Dakota, USA."
bibliography: ./references/references.bib
csl: ./references/american-medical-association.csl
header-includes: 
- \usepackage{placeins}
output:
  bookdown::pdf_document2: 
    fig_caption: yes
    keep_tex: yes
    toc: false
  bookdown::html_document2: 
    toc: false
    df_print: paged
    
---
*Jeff S. Wesner*^1^, *Dan Van Peursem*^2^, *José D. Flores*^2,3^, *Yuhlong Lio*^2^, *Chelsea A. Wesner*^3^

University of South Dakota 

^1^Department of Biology, ^2^Department of Mathematical Sciences, ^3^Department of Computer Science, ^3^Master of Public Health Program

<Jeff.Wesner@usd.edu>

Keywords: *Bayesian, COVID-19, Hospitalizations, SARS-CoV-2, Weibull*

# Abstract
Anticipating the number of hospital beds needed for patients with COVID-19 remains a challenge. Early efforts to predict hospital bed needs focused on deriving predictions from SIR models, largely at the level of countries, provinces, or states. In the United States, these models rely on data reported by state health agencies. However, predictive disease and hospitalization dynamics at the state level are complicated by geographic variation in disease parameters. In addition it is difficult to make forecasts early in a pandemic due to minimal data. However, Bayesian approaches that allow models to be specified with informed prior information from areas that have already completed a disease curve can serve as prior estimates for areas that are beginning their curve. Here, a Bayesian non-linear regression (Weibull function) was used to forecast cumulative and active COVID-19 hospitalizations for South Dakota, USA. As expected, early forecasts were dominated by prior information, which was derived from New York City. Importantly, hospitalization trends also differed within South Dakota due to early peaks in an urban area, followed by later peaks in other rural areas of the state. Combining these trends led to altered forecasts with relevant policy implications.

# Introduction
The novel coronavirus (SARS-CoV-2) was first detected in December 2019 in Wuhan, China and has since spread globally. The disease caused by SARS-CoV-2 (COVID-19) can lead to hospitalization or death in all age groups, but particularly in older age groups with comorbidities such as hypertension, obesity, and diabetes [@richardson_presenting_2020]. For example, in France, Salja et al.[@salje_estimating_2020] estimated that 3.6% of infected people become hospitalized, but that rate varies from a low of 0.001% to 10.1% for individuals that are <20 years old versus those >80 years old, respectively. A central challenge for hospitals is predicting how many hospitalizations will occur due to COVID-19, and whether hospital capacities will be exceeded. 

Predicting hospitalization needs due to COVID-19 may be particularly challenging in rural areas. For example, relative to urban areas, rural communities in the U.S. have reduced access to health care [@research_national_2016] and increased mortality from chronic diseases [@moy_leading_2017], both of which are key risk factors for COVID-19. South Dakota is among the most rural states in the U.S. with a 2017 population estimate of 869,666 [@bureau_acs_2017]. Of South Dakota’s 66 counties, 52% are frontier (with <15.5 persons per square kilometer) and 32% encompass or are comprised of reservation lands representing nine federally recognized tribes. Communites in rural areas also tend to have older populations. For example, among 56 U.S. counties with the largest proportion of people ages >85, all but two counties are rural and a county in South Dakota ranks first [@henning-smith_characteristics_2020]. South Dakota’s public health infrastructure is limited with a centralized state department of health that delivers public health services through a network of regional and county offices, most of which house a single public health nurse. Nearly 80% of nonprofit hospitals in South Dakota are critical access hospitals with 25 or fewer acute inpatient beds [@noauthor_doh_nodate], and acess to medical facilities with an intensive care unit (ICU) and ventilators is limited in rural areas [@casey_availability_2018].

To our knowledge, there are no published studies that model hospitalizations due to COVID-19 in rural and low resource settings. Developing new ways to model infectious disease outbreaks in jurisdictions with limited public health and health care infrastructure is critical to preventing and reducing mortality and morbidity in communities that are at high risk of COVID-19. Early predictions of hospitalization in the United States relied on projections from SIR models and their derivatives [@e_weissman_locally_2020]. Because they are developed primarily to simulate disease spread through a hypothetical, well-mixed population, SIR-based models require a number of assumptions to generate predictions of hospitalizations or death [@imperial_college_covid-19_response_team_estimating_2020]. Unlike many U.S. states, South Dakota has publically released hospitalization data daily and there is now enough data to model hospitalization curves directly, rather than infering hospitalizations through an SIR. 

Here, we modeled cumulative hospitalizations in an urban (Minnehaha) versus rural population within South Dakota using a Bayesian non-linear Weibull function. Because early predictions in a disease outbreak are critical for planning, but also are data limited, we used informed priors from New York City, which began its hospitalization curve before South Dakota. While New York City is not a rural area, the use of informed prior distributions allowed our model to make reasonable, though highly uncertain, forecasts of hospitalizations in a rural setting.
  
# Methods

**Data Retrieval**

We obtained data on cumulative hospitalizations and active hospitalizations (number hospitalized on a given day) from the data dashboard for the South Dakota Department of Health (SD DOH) - https://doh.sd.gov/news/Coronavirus.aspx#SD. Data for cumulative hospitalizations began on 2020-03-08 and were entered by hand into a .csv each day (SD DOH only reports totals for the current day, not a timeline). Data for active hospitalizations were not released until 2020-04-20, when 56 people were actively hospitalized. Beginning on that date, we also updated our .csv with active hospitalizations each day.

When data collection began, most cases and hospitalizations were located in Minnehaha County, South Dakota. Therefore, during data collection, we noted hospitalizations in Minnehaha County versus the rest of South Dakota to capture any potential divergent trends under the assumption that the disease would spread more slowly across rural South Dakota. For these two areas, data are only available for cumulative hospitalizations, not for active hospitalizations. Minnehaha County has a population density of 619 people per $km^2$, which is >50 times higher than the state average population density of 28 people per $km^2$ [@bureau_acs_2017]. Comparing these two areas allowed us to model COVID-19 hospitalizations in a rural and urban setting within the same state.

**Models**

We estimated cumulative hospitalizations using a Bayesian model in which hospitalizations were modeled as a sigmoid function of time using the Weibull function [@yang_potential_1978; @narushin_sigmoid_2003]. The Weibull function is derived from the Weibull cumulative distribution [@weibull_statistical_1951] and has been used widely in biology to model growth curves [@pielou_usefulness_1981]. We chose the Weibull function because it is more flexible than the logistic function and is asymmetric around the inflection point [@yang_potential_1978;@kumar_epidemiological_nodate]. We fit the Weibull function to two sets of data that describe 1) the cumulative hospitalizations for the state of South Dakota and 2) the cumulative hospitalizations for subgroups of Minnehaha County and the rest of South Dakota. Because the data were counts with positive outcomes, we used a Poisson likelihood with a log-link. 

*Model 1*

$$y_i \sim Poisson(\lambda_i)$$ 
$$log\lambda_i = \alpha_i\left(1 - exp\left(-\frac{x_i}{\beta_i}\right)^{\gamma_i}\right)$$

$$\alpha \sim \Gamma(64,8)$$
$$\beta \sim \Gamma(2.9, 0.18)$$
$$\gamma \sim \Gamma(5.8,4.8)$$

With the above notation, $y_i$ is the cumulative number of people hospitalized in South Dakota on the $i^{th}$ date, $\alpha$ is the asymptote, $\beta$ is the inflection point, and $\gamma$ is the slope at the inflection point. Gamma priors were used because each parameter must be positive and continuous.

Informative prior distributions were derived from the cumulative hospitalization curve in New York City (NYC Department of Health, https://www1.nyc.gov/site/doh/covid/covid-19-data.page). We derived the priors from New York City because NYC had nearly completed its hospitalization curve when South Dakota's was still beginning and because the data were available as a timeline (many states either have not reported temporal hospitalization data or have not made the data easily extractable).

To derive prior distributions for South Dakota, we first fit the aforementioned model to NYC's hospitalization curve. Before fitting the model, we multiplied NYC hospitalizations by 0.10 to put them on the scale of South Dakota's population (which is ~10% of NYC's population). We then fit the model to these adjusted hospitalizations using prior values of $\Gamma(1.2, 0.1)$ for $\alpha$, $\Gamma(0.25, 0.005)$ for $\beta$, and $\Gamma(1.4, 0.3)$ for $\gamma$. Those reflect prior distributions with wide standard deviations that would represent a potential overload of South Dakota's ~ 2000 hospital beds: 10,000 +/- 5000 (mean +/- sd) for $\alpha$, 50 +/- 100 for $\beta$, and 100 $\pm$ 50 for $\gamma$. 

*Model 2*

To capture trends inside and outside of Minnehaha County, we fit the same model as before, but included an indicator variable with two levels (Minnehaha County or Outside Minnehaha County) for each of the three parameters. 

$$y_i \sim Poisson(\lambda_i)$$
$$log\lambda_i = \alpha_j\left(1 - exp\left(-\frac{x_i}{\beta_j}\right)^{\gamma_j}\right)$$ 
$$\alpha_j = \alpha_{minn} + \alpha_{rest}r_i$$
$$\beta_j = \beta_{minn} + \beta_{rest}r_i$$
$$\gamma_j = \gamma_{minn} + \gamma_{rest}r_i$$
$$\alpha_{minn} \sim \Gamma(49,7)$$
$$\alpha_{rest} \sim N(0,1)$$
$$\beta_{minn} \sim \Gamma(2.9, 0.18)$$
$$\beta_{rest} \sim N(0, 5)$$
$$\gamma_{minn} \sim \Gamma(5.8, 4.8)$$
$$\gamma_{rest} \sim N(0,0.5)$$

With the above notation, $y_i$ is the cumulative number of people hospitalized in each *i* date ($x_i$),  $\alpha_j, \beta_j,$ and $\gamma_j$ are the parameters for each *j* group (Minnehaha County or the Rest of South Dakota), $X_{minn}$ are the priors for each X parameter ($\alpha$, $\beta$, $\gamma$), $X_{rest}$ are the priors for the difference in parameter values between Minnehaha and the Rest of South Dakota, and $r_i$ is an indicator variable that is 0 if the data are in Minnehaha County and 1 otherwise.

As before, prior values were chosen from a combination of prior information from NYC and from prior predictive simulation [@gabry_visualization_2019]. To do this, we simulated 300 cumulative hospitalization curves with mean values for each parameter derived from the fit of the NYC model. Because NYC has both a higher absolute population size and a higher population density (by 10-fold) than South Dakota, we adjusted prior means and standard deviations so that the prior predictive distributions estimated hospitalizations to have a maximum that is slightly below the maximum of NYC, but with standard deviations that still include positive prior probability for some extreme prediction (e.g., 50,000 cumulative hospitalizations). Figure \ref{prior:plot} shows the prior predictions for both models.

*Markov Chain Monte Carlo*

Each model aforementioned was specified in R (version 3.6.3; R Core Team 2020) using the *brms* package [@burkner_brms_nodate]. Posterior sampling was performed using Hamiltonian Monte Carlo in *rstan* (version 2.19.2, [@carpenter_stan_2017]). We fit four chains, each with 2000 iterations, discarding the first 1000 iterations of each chain as warm-up. Warm-up samples are similar to burn-in sampling, but are used in this case as an optimizer for the HMC algorithm. Chains were checked for convergence using trace plots to assure overlap (*Supplementary Information*), and by ensuring that the Gelman-Rubin convergence diagnostic $\hat{R}$ was < 1.1 [@gelman_inference_1992].

*Posterior prediction*

To forecast cumulative hospitalizations, we used the posterior predictive distributions from each model by first solving for the fitted values across each iteration of the posterior:

$$yfit_i^{(k)} = exp\left(\alpha_i^{(k)}\left(1 - exp\left(-\frac{x_i}{\beta_i^{(k)}}\right)^{\gamma_i^{(k)}}\right)\right)$$
where *k* is the $k^{th}$ iteration from the posterior distribution and *i* is the $i^{th}$ date. Posterior predicted values were estimated by drawing each $ypred_i^{(k)}$ from the Poisson distribution:

$$ypred_i^{(k)} = Poisson(yfit_i^{(k)})$$ 

We then summarized the mean, median, standard deviation and credible intervals (50 and 95%) across the posterior distribution of fitted and predicted values. For visualization, we plotted fitted values within the range of the data and predicted values beyond the range of the data. 

*Estimating Active Hospitalizations*

To estimate active hospitalizations from the cumulative hospitalization curve, we first derived daily incidence $\phi$ for each iteration of $yfit_i^{(k)}$ in which 

$$\phi_{i}^{(k)} = yfit_i^{(k)} - yfit_{i-1}^{(k)}$$

We then summed incidence over the previous 5, 10, 12, or 15 days to estimate variable lengths of hospital stays:
$$\omega_i^{(k)} = \phi_i^{(k)} + \phi_{i-1}^{(k)} + \phi_{i-2}^{(k)}...\phi_{i-n}^{(k)}$$

where $\omega_i^{(k)}$ is the number of people actively hospitalized on the $i^{th}$ day for the $k^{th}$ iteration, $\phi_i^{(k)}$ is the incidence on the $i^{th}$ day for the $k^{th}$ iteration and *n* is 5, 10, 12, or 15. These lengths of stay were chosen to capture the range of reported hopsital stay lengths from the literature [@rees_covid-19_2020]. 

We then plotted these predictions against active hospitalizations reported by the South Dakota Department of Health. For the group levels (*Model 2*), we performed the same calculations as above, but for each group. In addition, we also estimated the state-level hospitalizations from *Model 2* by summing the predictions from each group. This allowed us to compare predictions when only state-level data were available versus predictions with data available for different areas of the state.  

*Parameter change over time*

We re-fit the model each day as data were released. To visualize how parameter values changed over time as data were added, we plotted posterior predictions and parameter values from model runs in 20 day intervals. Twenty days was arbitrarily chosen to allow for visual clarity in the plots. 

# Results

At the state level, model 1 predicted a total of 876 hospitalizations (median) in South Dakota (90% CrI: 834-926, Table 2). The inflection point was predicted at 37 days after the first hospitalization, suggesting that the peak rate of hospitalizations occurred around April 20, 2020 (Table 2). In contrast, the model with group-level effects clearly showed that hospitalizations trends differed in Minnehaha County verses the rest of South Dakota (Figure \ref{post_all:plot}). In Minnehaha County, the inflection point occurred around day 23 and revealed an asymptote of 324 hospitalizations (90% CrI: 317-330) (Table 2). In the rest of South Dakota, the inflection point occurred ~40 days later (day 63, Figure \ref{post_all:plot}). Similarly, the maximum cumulative hospitalizations in the rest of South Dakota are estimated at a median of ~867, but with large uncertainty (90% CrI: 773-980, Table 2).   

As expected the uncertainty in predictions (Figure \ref{pred_overtime:plot}) improved over time as data were added to the model. The largest improvement appeared to occur during the model run on day 60, when all parameter values appeared to stabilize (*Supplementary Information*). After this date, predictions for hospitalizations in Minnehaha County were stable, while predictions outside of Minnehaha County tended to underpredict future hospitalizations until the most recent model runs (Figure \ref{pred_overtime:plot}).

Converting the cumulative curve to estimate the number of people actively hospitalized yields a maximum estimate of ~100 people actively hospitalized. This estimate is derived from the assumption that an average patient will spend 10 days in the hospital. That assumption appeared to best approximate the state reported data best (Figure \ref{active_daily_group:plot}). However, the state reported data also appear to be staying consistent at around 90 people hospitalized even when model 1 predicts that active hospitalizations should be declining (Figure \ref{active_daily_group:plot}). It is possible that some of the difference is due to underlying differences in hospitalizations in the two subgroups, but active hospitalization data are only available for the state, so we are unable to assess the accuracy of the group-level predictions (Figure \ref{active_daily_group:plot}).  

# Discussion

The most important result of this study is that modeling trends separately in urban versus rural parts of a state population reveal different projections of cumulative hospitalizations than if modeled only using state-level data. In particular, the model with urban vs. rural groups predicts that Minnehaha County will attain a maximum of ~316 hospitalizations, while areas outside of Minnehaha will attain a maximum of ~785. That results in approximately ~1000 people cumulatively hospitalized. In contrast, the model with only state-level data indicates a 24% smaller number of total people hospitalized (762). 

In addition to differences in maximum hospitalizations, the models predict different trends of active hospitalizations. Active hospitalizations are more relevant than cumulative hospitalizations for measuring hospital capacity. They have been modeled for the COVID pandemic in a variety of ways with many states adopting a version of an SIR model, such as the CHIME model [@e_weissman_locally_2020]. One challenge with estimating hospitalizations using an SIR-based approach is that they require estimates of a number of transition probabilities to convert infections into hospitalizations. These include estimating the proportion of infected people that become symptomatic, the proportion of those that require hospitalization, the proportion of those that seek hospitalization, the time lag between viral infection as modeled in an SIR, symptom onset, and actual hospitalization [@e_weissman_locally_2020; @imperial_college_covid-19_response_team_estimating_2020]. Early in an epidemic, when hospitalization data are scarce or absent, these models are essential for predicting possible hospitalization scenarios. However, once enough data are available on hospitalizations, it is possible to model the hospitalization curve directly, as we have done here.

Though we did not attempt to predict COVID-19 infections in South Dakota, it may be possible to use our approach to do so by treating infections as a latent variable that leads to subsequent hospitalizations. Flaxman et al. [@imperial_college_covid-19_response_team_estimating_2020] provide an example of this approach using COVID-19-related deaths rather than hospitalizations. By modeling the dynamics of deaths, they estimated a time-varying reproduction number ($R_t$), which was used to estimate the number of positive cases. Using deaths (or hospitalizations) to estimate infection dynamics may help to overcome limitations in testing capacity, which in turn lead to difficulty in linking publically-reported testing results to true population-level infection rates. This is particularly true in the United States, which has limited testing capacity and no centrally coordinated testing program [@schneider_failing_2020].

An advantage to the Bayesian approach is that we can use prior values of parameters in a model to fit a model with limited data. In our case, those parameters were conveniently available from New York City. However, if we were modeling a hospitalizaton curve that had no prior estimates, then we might derive priors from another epidemic that had similar disease characteristics or use prior predictive simulation to bound the model to reasonable prior predictions[@gabry_visualization_2019]. In particular, because the prior distributions for individual parameters may not be known or are difficult to interpret without the consideration of the likelihood [@gelman_prior_2017], it is important to assess the implications of prior choices using the prior predictive distribution (i.e. simulating potential from the prior distrbutions alone) [@gabry_visualization_2019] (Figure 1). In our model, data simulated from the prior helped to confirm that our model was specified in a way that included a wide range of hospitalization trajectories (Figure 1), but excluded extreme values that might have come from more diffuse priors, such as projecting asymptotes with hospitalizations that are higher than the population of South Dakota.   

# Data Availability Statement

All data and code are available at https://github.com/jswesner/covid_sd_ms [@wesner_jswesnercovid_sd_ms_2020]. These will be permanently archived via Zenodo upon acceptance of this manuscript.

# Acknowledgments

We declare no conflicts of interest. We thank the South Dakota Department of Health for making the hospitalization data publically available. This work is not affiliated with any funding agency.

# References
::: {#refs}
:::

\newpage  

\FloatBarrier

# Tables
 
```{r Load packages, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(scales)
library(ggridges)
library(here)
library(janitor)
library(viridis)
library(lubridate)
library(readr)
library(readxl)
library(cowplot)
library(kableExtra)
library(ggpubr)
library(rticles)
library(brms)
```


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
nycpostprior_table <- readRDS(file = here::here("plots/nycpostprior_table.rds")) %>% 
  mutate(Parameter = case_when(Parameter == "gamma" ~ "$\\gamma$",
                         Parameter == "beta" ~ "$\\beta$",
                         Parameter == "alpha" ~ "$\\alpha$",
                         Parameter == "gamma_rest" ~ "$\\gamma_{rest}$",
                         Parameter == "beta_rest" ~ "$\\beta_{rest}$",
                         Parameter == "alpha_rest" ~ "$\\alpha_{rest}$"),
         Model = fct_relevel(Model, "nyc","m1")) %>% 
  arrange(Parameter, Model)

kable(nycpostprior_table, "pandoc", caption = "Posterior distributions from the New York City model and prior distributions for the South Dakota models.") %>%
kable_styling(latex_options = c("striped", "hold_position"))
```

\newpage  

\FloatBarrier

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
table_all <- readRDS(file = here::here("plots/table_all.rds")) %>% 
  mutate(temp_param = paste(Model, Group, Parameter)) %>% 
  mutate(Parameter = case_when(temp_param == "Model 1 South Dakota inf" ~ "$\\beta$",
                         temp_param == "Model 1 South Dakota max" ~ "exp($\\alpha$)",
                         temp_param == "Model 1 South Dakota slope" ~ "$\\gamma$",
                         temp_param == "Model 2 Outside of Minnehaha slope"  ~ "$\\gamma_{minn} + \\gamma_{rest}$",
                         temp_param == "Model 2 Outside of Minnehaha inf" ~ "$\\beta_{minn} + \\beta_{rest}$",
                        temp_param == "Model 2 Outside of Minnehaha max"  ~ "exp($\\alpha_{minn} + \\alpha_{rest}$)",
                        temp_param == "Model 2 Minnehaha slope" ~ "$\\gamma_{minn}$",
                         temp_param == "Model 2 Minnehaha inf"  ~ "$\\beta_{minn}$",
                        temp_param == "Model 2 Minnehaha max"  ~ "exp($\\alpha_{minn}$)")) %>% 
  select(-temp_param)
  
  
kable(table_all, "pandoc", caption = "Summary statistics of model parameters. Asymptotes are exponentiated to place them on the scale of the response variable (cumulative hospitalizations). Summaries are derived from the posterior distributions of each parameter in the corresponding model.") %>%
kable_styling(latex_options = c("striped", "hold_position"))
```

\newpage  

\FloatBarrier

# Figures

```{r plot-nyc, echo=FALSE, fig.cap="Left: Model of New York City's hospitalization curve. Data are divided by 10 to reflect the relative population sizes in South Dakota versus New York city. Right: Three-hundred simulations of cumulative hospitalizations from the prior predictive distribution of each model for South Dakota. Priors for Model 1 were derived from the fit of NYC's hospitalization curve. Priors for Model 2 were similar to those of Model 1, but had a reduced prediction of cumulative hospitalizations to account for the smaller populations of each group (Minnehaha County vs Outside Minnehaha County) relative to the whole state population.\\label{prior:plot}", fig.height=4, fig.width=12, message=FALSE, warning=FALSE, paged.print=FALSE}
prior_plots <- readRDS(here::here("plots/prior_plots.rds"))
prior_plots
```

```{r , echo=FALSE, fig.cap="Posterior distributions of cumulative hospitalizations in South Dakota. Lines indicate medians and shading indicates the 50 and 90% intervals. Predictions beyond the data represent samples from the posterior predictive distribution. Predictions within the data represent samples from the posterior fitted distribution.\\label{post_all:plot}", fig.height=6, fig.width=6, message=FALSE, warning=FALSE, paged.print=FALSE}
post_all_plot <- readRDS(here::here("plots/post_all_plot.rds"))
post_all_plot
```

```{r echo=FALSE, fig.cap="Change in predictions over time as models are fit using data at days 20, 40, 60, 80, 100, and 120. Data points show the full hospitalization curve (same for each panel). The size of the data points changes based on what data were used to fit the model versus the actual data obtained after a given model was fit.\\label{pred_overtime:plot}", fig.height=8, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}
pred_overtime <- readRDS(here::here("plots/pred_overtime.rds"))
pred_overtime
```

```{r echo=FALSE, fig.cap="Posterior predictive distributions of active hospitalizations in South Dakota. Lines indicate medians and shading indicates the 50 and 95% prediction intervals.\\label{active_daily_group:plot}", fig.height=10, fig.width=10, message=FALSE, warning=FALSE, paged.print=FALSE}
active_daily_group <- readRDS(here::here("plots/active_daily_group.rds"))
active_daily_group
```

\newpage  

\FloatBarrier

# Supplementary Information
Here we compare the prior and posterior distributions of each parameter in the models. Figure S1 indicates how much information was learned about each parameter from adding data. Trace plots indicate well-mixed chains for each model.

```{r echo=FALSE, fig.cap="Comparison of prior and posterior distributions for each parameter in models 1 and 2.", fig.height=4, fig.width=12, message=FALSE, warning=FALSE, paged.print=FALSE}
prior_post_all <- readRDS(here::here("plots/prior_post_all.rds"))
prior_post_all
```

```{r echo=FALSE, fig.cap="Change in parameter values over time. Violins represent posterior distributions of parameter values over time as models are fit using data at day 0, 20, 40, 60, 80, 100, and the most recent date.\\label{param_time_plot:plot}", fig.height=5, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}
param_time_plot <- readRDS(here::here("plots/param_time_plot.rds"))
param_time_plot
```

\newpage  

\FloatBarrier

# Trace Plots

*Model 1*
```{r echo=FALSE, fig.cap="Posterior distributions and trace plots for each parameter from Model 1.", fig.height=5, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}

trace1 <- readRDS(here::here("plots/trace1.rds"))
trace1
```

*Model 2*
```{r echo=FALSE, fig.cap="Posterior distributions and trace plots for each parameter from Model 2.", fig.height=10, fig.width=8, message=FALSE, warning=FALSE, paged.print=FALSE}
trace2 <- readRDS(here::here("plots/trace2.rds"))
trace2
```

\newpage  

\FloatBarrier

# Stan code
Model code in the Stan language is below.

*Model 1*
```{r Model 1, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
mod1 <- readRDS(here::here("outputs/fit_weib_state.rds"))
stancode(mod1)
```

\newpage  

\FloatBarrier

*Model 2*
```{r Model 2, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
mod2 <- readRDS(here::here("outputs/fit_weib_group_f.rds"))
stancode(mod2)
```
